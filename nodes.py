"""
åˆ†è¾¨ç‡é¢„è®¾ä¸å·¥å…·èŠ‚ç‚¹ - ä¸“ä¸šç‰ˆ
åŒ…å«æ‰€æœ‰å°ºå¯¸å¤„ç†åŠŸèƒ½çš„ä¸“ä¸šå®ç°
"""
import torch
from typing import Dict, Any, Tuple
from .presets import get_size_from_preset, PRESETS, CROP_METHODS, RESIZE_ALGOS
from .utils import ImageUtils

class BaseResolutionNode:
    """åŸºç¡€åˆ†è¾¨ç‡èŠ‚ç‚¹ - æä¾›å…¬å…±åŠŸèƒ½"""
    
    @classmethod
    def get_preset_inputs(cls) -> Dict[str, Any]:
        """è·å–é¢„è®¾è¾“å…¥é€‰é¡¹"""
        return {
            k: (["å…³"] + [name for name, _ in v], {"default": "å…³"})
            for k, v in PRESETS.items()
        }
    
    @staticmethod
    def validate_resolution(width: int, height: int, min_size: int = 64, max_size: int = 8192) -> Tuple[int, int]:
        """éªŒè¯åˆ†è¾¨ç‡æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…"""
        width = max(min_size, min(width, max_size))
        height = max(min_size, min(height, max_size))
        return width, height

# ========== ä¸“ä¸šåˆ†è¾¨ç‡å¤„ç†èŠ‚ç‚¹ ==========

class ResolutionPresetImage(BaseResolutionNode):
    """åˆ†è¾¨ç‡é¢„è®¾ - å›¾åƒå¤„ç†"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                **cls.get_preset_inputs(),
                "è£å‰ªæ–¹å¼": (CROP_METHODS, {"default": "ä¸­å¿ƒè£å‰ª"}),
                "ç¼©æ”¾ç®—æ³•": (RESIZE_ALGOS, {"default": "lanczos"}),
                "å¯ç”¨è¾¹é•¿ç¼©æ”¾": ("BOOLEAN", {"default": False}),
                "ç¼©æ”¾åŸºå‡†": (["æœ€é•¿è¾¹", "æœ€çŸ­è¾¹"], {"default": "æœ€é•¿è¾¹"}),
                "ç¼©æ”¾é•¿åº¦": ("INT", {
                    "default": 1024,
                    "min": 64,
                    "max": 8192,
                    "step": 8
                }),
            },
            "optional": {
                "å›¾åƒè¾“å…¥": ("IMAGE",),
                "é®ç½©è¾“å…¥": ("MASK",),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK", "INT", "INT")
    RETURN_NAMES = ("å›¾åƒè¾“å‡º", "é®ç½©è¾“å‡º", "å®½åº¦", "é«˜åº¦")
    FUNCTION = "process_image"
    CATEGORY = "ResolutionPresets"
    
    def process_image(self, å›¾åƒè¾“å…¥=None, é®ç½©è¾“å…¥=None, **kwargs):
        use_edge = kwargs["å¯ç”¨è¾¹é•¿ç¼©æ”¾"]
        edge_mode = kwargs["ç¼©æ”¾åŸºå‡†"]
        target_len = kwargs["ç¼©æ”¾é•¿åº¦"]
        crop = kwargs["è£å‰ªæ–¹å¼"]
        algo = kwargs["ç¼©æ”¾ç®—æ³•"]
        
        # è¾¹é•¿ç¼©æ”¾æ¨¡å¼
        if use_edge:
            if å›¾åƒè¾“å…¥ is not None:
                pil_img = ImageUtils.tensor_to_pil(å›¾åƒè¾“å…¥)
                pil_img = ImageUtils.resize_by_edge(pil_img, edge_mode, target_len)
                å›¾åƒè¾“å‡º = ImageUtils.pil_to_tensor(pil_img)
                out_w, out_h = pil_img.size
            else:
                å›¾åƒè¾“å‡º = torch.zeros((1, 3, 512, 512), dtype=torch.float32)
                out_w, out_h = 512, 512
            
            if é®ç½©è¾“å…¥ is not None:
                pil_msk = ImageUtils.tensor_to_pil(é®ç½©è¾“å…¥, is_mask=True)
                pil_msk = ImageUtils.resize_by_edge(pil_msk, edge_mode, target_len)
                é®ç½©è¾“å‡º = ImageUtils.pil_to_tensor(pil_msk, is_mask=True)
            else:
                é®ç½©è¾“å‡º = torch.zeros((1, 1, out_h, out_w), dtype=torch.float32)
            
            return (å›¾åƒè¾“å‡º, é®ç½©è¾“å‡º, out_w, out_h)
        
        # é¢„è®¾åˆ†è¾¨ç‡æ¨¡å¼
        choices = {k: kwargs[k] for k in PRESETS}
        w, h = get_size_from_preset(choices)
        
        if å›¾åƒè¾“å…¥ is not None:
            pil_img = ImageUtils.tensor_to_pil(å›¾åƒè¾“å…¥)
            pil_img = ImageUtils.resize_with_crop(pil_img, w, h, crop, algo)
            å›¾åƒè¾“å‡º = ImageUtils.pil_to_tensor(pil_img)
        else:
            å›¾åƒè¾“å‡º = torch.zeros((1, 3, h, w), dtype=torch.float32)
        
        if é®ç½©è¾“å…¥ is not None:
            pil_msk = ImageUtils.tensor_to_pil(é®ç½©è¾“å…¥, is_mask=True)
            pil_msk = ImageUtils.resize_with_crop(pil_msk, w, h, crop, algo)
            é®ç½©è¾“å‡º = ImageUtils.pil_to_tensor(pil_msk, is_mask=True)
        else:
            é®ç½©è¾“å‡º = torch.zeros((1, 1, h, w), dtype=torch.float32)
        
        return (å›¾åƒè¾“å‡º, é®ç½©è¾“å‡º, w, h)

class ResolutionPresetLatent(BaseResolutionNode):
    """åˆ†è¾¨ç‡é¢„è®¾ - æ½œåœ¨ç©ºé—´"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                **cls.get_preset_inputs(),
                "å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡": ("BOOLEAN", {"default": False}),
                "å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
            }
        }
    
    RETURN_TYPES = ("LATENT",)
    RETURN_NAMES = ("æ½œåœ¨ç©ºé—´",)
    FUNCTION = "create_latent"
    CATEGORY = "ResolutionPresets"
    
    def create_latent(self, **kwargs):
        use_custom = kwargs["å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡"]
        
        if use_custom:
            w, h = kwargs["å®½åº¦"], kwargs["é«˜åº¦"]
        else:
            choices = {k: kwargs[k] for k in PRESETS}
            w, h = get_size_from_preset(choices)
        
        # éªŒè¯åˆ†è¾¨ç‡å¹¶åˆ›å»ºæ½œåœ¨ç©ºé—´å¼ é‡
        w, h = self.validate_resolution(w, h)
        latent = torch.zeros([1, 4, h // 8, w // 8])
        return ({"samples": latent},)

class ResolutionPresetSetter(BaseResolutionNode):
    """åˆ†è¾¨ç‡é¢„è®¾å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                **cls.get_preset_inputs(),
                "å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡": ("BOOLEAN", {"default": False}),
                "å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
            }
        }
    
    RETURN_TYPES = ("INT", "INT")
    RETURN_NAMES = ("å®½åº¦", "é«˜åº¦")
    FUNCTION = "get_resolution"
    CATEGORY = "ResolutionPresets"
    
    def get_resolution(self, **kwargs):
        use_custom = kwargs["å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡"]
        
        if use_custom:
            w, h = kwargs["å®½åº¦"], kwargs["é«˜åº¦"]
        else:
            choices = {k: kwargs[k] for k in PRESETS}
            w, h = get_size_from_preset(choices)
        
        return self.validate_resolution(w, h)

# ========== æ™ºèƒ½åˆ†è¾¨ç‡å·¥å…· ==========

class ResolutionCalculator(BaseResolutionNode):
    """åˆ†è¾¨ç‡è®¡ç®—å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                "åŸå§‹å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "åŸå§‹é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "ç¼©æ”¾æ¨¡å¼": (["æŒ‰æ¯”ä¾‹", "æŒ‰é•¿å®½æ¯”", "å›ºå®šåˆ†è¾¨ç‡"], {"default": "æŒ‰æ¯”ä¾‹"}),
                "ç¼©æ”¾æ¯”ä¾‹": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 4.0, "step": 0.1}),
                "ç›®æ ‡é•¿å®½æ¯”": ([
                    "ä¿æŒåŸæ¯”ä¾‹", "1:1", "4:3", "3:2", "16:9", 
                    "3:4", "2:3", "9:16", "21:9"
                ], {"default": "ä¿æŒåŸæ¯”ä¾‹"}),
                "æœ€å¤§è¾¹é•¿é™åˆ¶": ("INT", {"default": 4096, "min": 512, "max": 8192, "step": 8}),
                "ç¡®ä¿8çš„å€æ•°": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("INT", "INT", "STRING")
    RETURN_NAMES = ("å®½åº¦", "é«˜åº¦", "åˆ†è¾¨ç‡ä¿¡æ¯")
    FUNCTION = "calculate_resolution"
    CATEGORY = "ResolutionPresets"
    
    def calculate_resolution(self, **kwargs):
        width = kwargs["åŸå§‹å®½åº¦"]
        height = kwargs["åŸå§‹é«˜åº¦"]
        mode = kwargs["ç¼©æ”¾æ¨¡å¼"]
        scale = kwargs["ç¼©æ”¾æ¯”ä¾‹"]
        aspect = kwargs["ç›®æ ‡é•¿å®½æ¯”"]
        max_side = kwargs["æœ€å¤§è¾¹é•¿é™åˆ¶"]
        ensure_multiple = kwargs["ç¡®ä¿8çš„å€æ•°"]
        
        if mode == "å›ºå®šåˆ†è¾¨ç‡":
            new_width, new_height = width, height
        elif mode == "æŒ‰é•¿å®½æ¯”" and aspect != "ä¿æŒåŸæ¯”ä¾‹":
            # è§£æé•¿å®½æ¯”
            if ":" in aspect:
                w_ratio, h_ratio = map(int, aspect.split(":"))
                new_width, new_height = ImageUtils.calculate_optimal_size(
                    width, height,
                    target_aspect_ratio=(w_ratio, h_ratio),
                    max_side=max_side,
                    multiple_of=8 if ensure_multiple else 1
                )
            else:
                new_width, new_height = width, height
        else:
            # æŒ‰æ¯”ä¾‹ç¼©æ”¾
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            # åº”ç”¨æœ€å¤§è¾¹é•¿é™åˆ¶
            if max(new_width, new_height) > max_side:
                scale_factor = max_side / max(new_width, new_height)
                new_width = int(new_width * scale_factor)
                new_height = int(new_height * scale_factor)
        
        # ç¡®ä¿æ˜¯8çš„å€æ•°
        if ensure_multiple:
            new_width = new_width - (new_width % 8)
            new_height = new_height - (new_height % 8)
        
        # è·å–åˆ†è¾¨ç‡ä¿¡æ¯
        info = ImageUtils.get_resolution_info(new_width, new_height)
        info_str = (
            f"ğŸ“ åˆ†è¾¨ç‡: {new_width} Ã— {new_height}\n"
            f"ğŸ”³ é•¿å®½æ¯”: {info['aspect_name']}\n"
            f"ğŸ“Š åƒç´ : {info['megapixels']} MP ({info['resolution_level']})\n"
            f"ğŸ“± æ–¹å‘: {'æ¨ªç‰ˆ ğŸŒ„' if info['is_landscape'] else 'ç«–ç‰ˆ ğŸ“±' if info['is_portrait'] else 'æ­£æ–¹å½¢ â¬œ'}"
        )
        
        return (new_width, new_height, info_str)

class ResolutionAnalyzer(BaseResolutionNode):
    """åˆ†è¾¨ç‡åˆ†æå™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                "å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "è¯¦ç»†æ¨¡å¼": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("åŸºæœ¬ä¿¡æ¯", "è¯¦ç»†åˆ†æ")
    FUNCTION = "analyze_resolution"
    CATEGORY = "ResolutionPresets"
    
    def analyze_resolution(self, å®½åº¦, é«˜åº¦, è¯¦ç»†æ¨¡å¼):
        info = ImageUtils.get_resolution_info(å®½åº¦, é«˜åº¦)
        
        # åŸºæœ¬ä¿¡æ¯
        basic_info = (
            f"åˆ†è¾¨ç‡: {info['width']}Ã—{info['height']} "
            f"({info['aspect_name']})\n"
            f"åƒç´ : {info['megapixels']}MP â€¢ ç­‰çº§: {info['resolution_level']}"
        )
        
        # è¯¦ç»†åˆ†æ
        if è¯¦ç»†æ¨¡å¼:
            detailed_info = self._generate_detailed_analysis(info)
        else:
            detailed_info = "è¯¦ç»†åˆ†æå·²å…³é—­"
        
        return (basic_info, detailed_info)
    
    def _generate_detailed_analysis(self, info: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†è¾¨ç‡åˆ†æ"""
        w, h = info['width'], info['height']
        mp = info['megapixels']
        aspect = info['aspect_ratio']
        
        analysis_lines = []
        analysis_lines.append("ğŸ“Š è¯¦ç»†åˆ†è¾¨ç‡åˆ†æ")
        analysis_lines.append("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        # åŸºç¡€ä¿¡æ¯
        analysis_lines.append(f"â€¢ å®½åº¦: {w:,} åƒç´ ")
        analysis_lines.append(f"â€¢ é«˜åº¦: {h:,} åƒç´ ")
        analysis_lines.append(f"â€¢ æ€»åƒç´ : {info['total_pixels']:,}")
        analysis_lines.append(f"â€¢ ç™¾ä¸‡åƒç´ : {mp:.2f} MP")
        analysis_lines.append(f"â€¢ é•¿å®½æ¯”: {info['aspect_name']} ({aspect:.3f})")
        
        # å»ºè®®ç”¨é€”
        analysis_lines.append("\nğŸ’¡ å»ºè®®ç”¨é€”:")
        if mp < 0.5:
            analysis_lines.append("  âœ“ å›¾æ ‡ã€å°å°ºå¯¸å›¾ç‰‡")
            analysis_lines.append("  âœ“ ä½åˆ†è¾¨ç‡é¢„è§ˆå›¾")
        elif mp < 2.0:
            analysis_lines.append("  âœ“ ç¤¾äº¤åª’ä½“åˆ†äº«")
            analysis_lines.append("  âœ“ ç½‘é¡µå›¾ç‰‡å±•ç¤º")
            analysis_lines.append("  âœ“ æ‰‹æœºå£çº¸")
        elif mp < 5.0:
            analysis_lines.append("  âœ“ é«˜æ¸…å£çº¸")
            analysis_lines.append("  âœ“ å°åˆ·å“ï¼ˆå°å°ºå¯¸ï¼‰")
            analysis_lines.append("  âœ“ ä¸“ä¸šæ‘„å½±å±•ç¤º")
        elif mp < 10.0:
            analysis_lines.append("  âœ“ 4Kæ˜¾ç¤ºå™¨å£çº¸")
            analysis_lines.append("  âœ“ ä¸­ç­‰å°ºå¯¸å°åˆ·")
            analysis_lines.append("  âœ“ é«˜è´¨é‡æ•°å­—å†…å®¹")
        else:
            analysis_lines.append("  âœ“ å¤§å¹…é¢å°åˆ·å“")
            analysis_lines.append("  âœ“ è¶…é«˜ç²¾åº¦éœ€æ±‚")
            analysis_lines.append("  âœ“ ä¸“ä¸šæ‘„å½±åæœŸ")
        
        # æŠ€æœ¯å»ºè®®
        analysis_lines.append("\nğŸ”§ æŠ€æœ¯å»ºè®®:")
        if info['is_landscape']:
            analysis_lines.append("  â€¢ é€‚åˆæ¨ªç‰ˆå†…å®¹å±•ç¤º")
        elif info['is_portrait']:
            analysis_lines.append("  â€¢ é€‚åˆç«–ç‰ˆç§»åŠ¨ç«¯å†…å®¹")
        else:
            analysis_lines.append("  â€¢ é€‚åˆç¤¾äº¤åª’ä½“å¤´åƒã€å›¾æ ‡")
        
        # æ¨¡å‹åŒ¹é…å»ºè®®
        analysis_lines.append("\nğŸ¤– AIæ¨¡å‹åŒ¹é…:")
        if w == h:
            analysis_lines.append("  â€¢ é€‚åˆæ‰€æœ‰æ¨¡å‹çš„1:1ç”Ÿæˆ")
        elif abs(aspect - 1.777) < 0.1:  # æ¥è¿‘16:9
            analysis_lines.append("  â€¢ é€‚åˆFLUXã€SDXLçš„è§†é¢‘æ¯”ä¾‹")
        elif abs(aspect - 0.667) < 0.1:  # æ¥è¿‘2:3
            analysis_lines.append("  â€¢ é€‚åˆSDXLã€QWENçš„ç«–ç‰ˆæ¯”ä¾‹")
        
        analysis_lines.append("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        analysis_lines.append(f"ç”Ÿæˆæ—¶é—´å»ºè®®: {self._get_render_time_estimate(mp)}")
        
        return "\n".join(analysis_lines)
    
    def _get_render_time_estimate(self, megapixels: float) -> str:
        """æ ¹æ®åƒç´ æ•°ä¼°ç®—æ¸²æŸ“æ—¶é—´"""
        if megapixels < 1.0:
            return "å¿«é€Ÿï¼ˆæ•°ç§’ï¼‰"
        elif megapixels < 4.0:
            return "ä¸­ç­‰ï¼ˆ10-30ç§’ï¼‰"
        elif megapixels < 10.0:
            return "è¾ƒæ…¢ï¼ˆ30-60ç§’ï¼‰"
        else:
            return "è¾ƒæ…¢ï¼ˆå¯èƒ½éœ€è¦1åˆ†é’Ÿä»¥ä¸Šï¼‰"

# ========== å®ç”¨å·¥å…·èŠ‚ç‚¹ ==========

class AspectRatioCalculator(BaseResolutionNode):
    """é•¿å®½æ¯”è®¡ç®—å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                "å®½åº¦": ("INT", {"default": 1920, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1080, "min": 64, "max": 8192, "step": 8}),
            }
        }
    
    RETURN_TYPES = ("FLOAT", "STRING")
    RETURN_NAMES = ("é•¿å®½æ¯”å€¼", "é•¿å®½æ¯”æè¿°")
    FUNCTION = "calculate_aspect"
    CATEGORY = "ResolutionPresets"
    
    def calculate_aspect(self, å®½åº¦, é«˜åº¦):
        # è®¡ç®—æœ€å¤§å…¬çº¦æ•°
        def gcd(a, b):
            while b:
                a, b = b, a % b
            return a
        
        w, h = å®½åº¦, é«˜åº¦
        divisor = gcd(w, h)
        ratio_w = w // divisor
        ratio_h = h // divisor
        aspect_ratio = w / h
        
        # å¸¸è§é•¿å®½æ¯”è¯†åˆ«
        common_ratios = {
            1.0: "1:1 (æ­£æ–¹å½¢)",
            1.3333: "4:3 (ä¼ ç»Ÿç”µè§†)",
            1.5: "3:2 (ä¼ ç»Ÿèƒ¶ç‰‡)",
            1.7778: "16:9 (é«˜æ¸…è§†é¢‘)",
            1.6: "16:10 (æ˜¾ç¤ºå™¨)",
            0.6667: "2:3 (ç«–ç‰ˆç…§ç‰‡)",
            0.75: "3:4 (ç«–ç‰ˆç…§ç‰‡)",
            0.5625: "9:16 (æ‰‹æœºç«–å±)",
            2.3333: "21:9 (ç”µå½±è¶…å®½å±)",
        }
        
        # æ‰¾åˆ°æœ€æ¥è¿‘çš„å¸¸è§é•¿å®½æ¯”
        closest_ratio = min(common_ratios.keys(), key=lambda x: abs(x - aspect_ratio))
        if abs(closest_ratio - aspect_ratio) < 0.01:
            description = common_ratios[closest_ratio]
        else:
            description = f"{ratio_w}:{ratio_h} (è‡ªå®šä¹‰æ¯”ä¾‹)"
        
        return (float(aspect_ratio), description)

# ========== èŠ‚ç‚¹æ³¨å†Œ ==========

NODE_CLASS_MAPPINGS = {
    # ä¸»åŠŸèƒ½èŠ‚ç‚¹
    "ResolutionPresetImage": ResolutionPresetImage,
    "ResolutionPresetLatent": ResolutionPresetLatent,
    "ResolutionPresetSetter": ResolutionPresetSetter,
    
    # å·¥å…·èŠ‚ç‚¹
    "ResolutionCalculator": ResolutionCalculator,
    "ResolutionAnalyzer": ResolutionAnalyzer,
    "AspectRatioCalculator": AspectRatioCalculator,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    # ä¸»åŠŸèƒ½èŠ‚ç‚¹
    "ResolutionPresetImage": "åˆ†è¾¨ç‡é¢„è®¾ - å›¾åƒ",
    "ResolutionPresetLatent": "åˆ†è¾¨ç‡é¢„è®¾ - æ½œåœ¨ç©ºé—´",
    "ResolutionPresetSetter": "åˆ†è¾¨ç‡é¢„è®¾å™¨",
    
    # å·¥å…·èŠ‚ç‚¹
    "ResolutionCalculator": "åˆ†è¾¨ç‡è®¡ç®—å™¨",
    "ResolutionAnalyzer": "åˆ†è¾¨ç‡åˆ†æå™¨",
    "AspectRatioCalculator": "é•¿å®½æ¯”è®¡ç®—å™¨",
}