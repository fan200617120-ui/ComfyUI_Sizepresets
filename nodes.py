"""
åˆ†è¾¨ç‡é¢„è®¾ä¸å·¥å…·èŠ‚ç‚¹ - ä¸“ä¸šç‰ˆ
æ–‡ä»¶å¤¹åï¼šComfyUI_Sizepresets
èŠ‚ç‚¹æ˜¾ç¤ºåï¼šä¸“ä¸šåˆ†è¾¨ç‡èŠ‚ç‚¹
"""
import torch
from typing import Dict, Any, Tuple
from .presets import get_size_from_preset, PRESETS, CROP_METHODS, RESIZE_ALGOS
from .utils import ImageUtils

class BaseResolutionNode:
    """åŸºç¡€åˆ†è¾¨ç‡èŠ‚ç‚¹"""
    
    @classmethod
    def get_preset_inputs(cls) -> Dict[str, Any]:
        return {
            k: (["å…³"] + [name for name, _ in v], {"default": "å…³"})
            for k, v in PRESETS.items()
        }
    
    @staticmethod
    def validate_resolution(width: int, height: int, min_size: int = 64, max_size: int = 8192) -> Tuple[int, int]:
        width = max(min_size, min(width, max_size))
        height = max(min_size, min(height, max_size))
        return width, height

# ========== æ ¸å¿ƒèŠ‚ç‚¹ï¼šä¿æŒä¸“ä¸šæ˜¾ç¤ºå ==========

class ResolutionPresetImage(BaseResolutionNode):
    """åˆ†è¾¨ç‡é¢„è®¾ - å›¾åƒå¤„ç†"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                **cls.get_preset_inputs(),
                "è£å‰ªæ–¹å¼": (CROP_METHODS, {"default": "ä¸­å¿ƒè£å‰ª"}),
                "ç¼©æ”¾ç®—æ³•": (RESIZE_ALGOS, {"default": "lanczos"}),
                "å¯ç”¨è¾¹é•¿ç¼©æ”¾": ("BOOLEAN", {"default": False}),
                "ç¼©æ”¾åŸºå‡†": (["æœ€é•¿è¾¹", "æœ€çŸ­è¾¹"], {"default": "æœ€é•¿è¾¹"}),
                "ç¼©æ”¾é•¿åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
            },
            "optional": {
                "å›¾åƒè¾“å…¥": ("IMAGE",),
                "é®ç½©è¾“å…¥": ("MASK",),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK", "INT", "INT")
    RETURN_NAMES = ("å›¾åƒè¾“å‡º", "é®ç½©è¾“å‡º", "å®½åº¦", "é«˜åº¦")
    FUNCTION = "process_image"
    CATEGORY = "ResolutionPresets"  # ä¸“ä¸šåˆ†ç±»å
    
    def process_image(self, å›¾åƒè¾“å…¥=None, é®ç½©è¾“å…¥=None, **kwargs):
        use_edge = kwargs["å¯ç”¨è¾¹é•¿ç¼©æ”¾"]
        edge_mode = kwargs["ç¼©æ”¾åŸºå‡†"]
        target_len = kwargs["ç¼©æ”¾é•¿åº¦"]
        crop = kwargs["è£å‰ªæ–¹å¼"]
        algo = kwargs["ç¼©æ”¾ç®—æ³•"]
        
        if use_edge:
            if å›¾åƒè¾“å…¥ is not None:
                pil_img = ImageUtils.tensor_to_pil(å›¾åƒè¾“å…¥)
                pil_img = ImageUtils.resize_by_edge(pil_img, edge_mode, target_len)
                å›¾åƒè¾“å‡º = ImageUtils.pil_to_tensor(pil_img)
                out_w, out_h = pil_img.size
            else:
                å›¾åƒè¾“å‡º = torch.zeros((1, 3, 512, 512), dtype=torch.float32)
                out_w, out_h = 512, 512
            
            if é®ç½©è¾“å…¥ is not None:
                pil_msk = ImageUtils.tensor_to_pil(é®ç½©è¾“å…¥, is_mask=True)
                pil_msk = ImageUtils.resize_by_edge(pil_msk, edge_mode, target_len)
                é®ç½©è¾“å‡º = ImageUtils.pil_to_tensor(pil_msk, is_mask=True)
            else:
                é®ç½©è¾“å‡º = torch.zeros((1, 1, out_h, out_w), dtype=torch.float32)
            
            return (å›¾åƒè¾“å‡º, é®ç½©è¾“å‡º, out_w, out_h)
        
        choices = {k: kwargs[k] for k in PRESETS}
        w, h = get_size_from_preset(choices)
        
        if å›¾åƒè¾“å…¥ is not None:
            pil_img = ImageUtils.tensor_to_pil(å›¾åƒè¾“å…¥)
            pil_img = ImageUtils.resize_with_crop(pil_img, w, h, crop, algo)
            å›¾åƒè¾“å‡º = ImageUtils.pil_to_tensor(pil_img)
        else:
            å›¾åƒè¾“å‡º = torch.zeros((1, 3, h, w), dtype=torch.float32)
        
        if é®ç½©è¾“å…¥ is not None:
            pil_msk = ImageUtils.tensor_to_pil(é®ç½©è¾“å…¥, is_mask=True)
            pil_msk = ImageUtils.resize_with_crop(pil_msk, w, h, crop, algo)
            é®ç½©è¾“å‡º = ImageUtils.pil_to_tensor(pil_msk, is_mask=True)
        else:
            é®ç½©è¾“å‡º = torch.zeros((1, 1, h, w), dtype=torch.float32)
        
        return (å›¾åƒè¾“å‡º, é®ç½©è¾“å‡º, w, h)

class ResolutionPresetLatent(BaseResolutionNode):
    """åˆ†è¾¨ç‡é¢„è®¾ - æ½œåœ¨ç©ºé—´"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                **cls.get_preset_inputs(),
                "å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡": ("BOOLEAN", {"default": False}),
                "å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
            }
        }
    
    RETURN_TYPES = ("LATENT",)
    RETURN_NAMES = ("æ½œåœ¨ç©ºé—´",)
    FUNCTION = "create_latent"
    CATEGORY = "ResolutionPresets"
    
    def create_latent(self, **kwargs):
        use_custom = kwargs["å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡"]
        
        if use_custom:
            w, h = kwargs["å®½åº¦"], kwargs["é«˜åº¦"]
        else:
            choices = {k: kwargs[k] for k in PRESETS}
            w, h = get_size_from_preset(choices)
        
        w, h = self.validate_resolution(w, h)
        latent = torch.zeros([1, 4, h // 8, w // 8])
        return ({"samples": latent},)

class ResolutionPresetSetter(BaseResolutionNode):
    """åˆ†è¾¨ç‡é¢„è®¾å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                **cls.get_preset_inputs(),
                "å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡": ("BOOLEAN", {"default": False}),
                "å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
            }
        }
    
    RETURN_TYPES = ("INT", "INT")
    RETURN_NAMES = ("å®½åº¦", "é«˜åº¦")
    FUNCTION = "get_resolution"
    CATEGORY = "ResolutionPresets"
    
    def get_resolution(self, **kwargs):
        use_custom = kwargs["å¯ç”¨è‡ªå®šä¹‰åˆ†è¾¨ç‡"]
        
        if use_custom:
            w, h = kwargs["å®½åº¦"], kwargs["é«˜åº¦"]
        else:
            choices = {k: kwargs[k] for k in PRESETS}
            w, h = get_size_from_preset(choices)
        
        return self.validate_resolution(w, h)

# ========== å·¥å…·èŠ‚ç‚¹ ==========

class ResolutionCalculator(BaseResolutionNode):
    """åˆ†è¾¨ç‡è®¡ç®—å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                "åŸå§‹å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "åŸå§‹é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "ç¼©æ”¾æ¨¡å¼": (["æŒ‰æ¯”ä¾‹", "æŒ‰é•¿å®½æ¯”", "å›ºå®šåˆ†è¾¨ç‡"], {"default": "æŒ‰æ¯”ä¾‹"}),
                "ç¼©æ”¾æ¯”ä¾‹": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 4.0, "step": 0.1}),
                "ç›®æ ‡é•¿å®½æ¯”": (["ä¿æŒåŸæ¯”ä¾‹", "1:1", "4:3", "3:2", "16:9", "3:4", "2:3", "9:16", "21:9"], {"default": "ä¿æŒåŸæ¯”ä¾‹"}),
                "æœ€å¤§è¾¹é•¿é™åˆ¶": ("INT", {"default": 4096, "min": 512, "max": 8192, "step": 8}),
                "ç¡®ä¿8çš„å€æ•°": ("BOOLEAN", {"default": True}),
            }
        }
    
    RETURN_TYPES = ("INT", "INT", "STRING")
    RETURN_NAMES = ("å®½åº¦", "é«˜åº¦", "åˆ†è¾¨ç‡ä¿¡æ¯")
    FUNCTION = "calculate_resolution"
    CATEGORY = "ResolutionPresets"
    
    def calculate_resolution(self, **kwargs):
        width = kwargs["åŸå§‹å®½åº¦"]
        height = kwargs["åŸå§‹é«˜åº¦"]
        mode = kwargs["ç¼©æ”¾æ¨¡å¼"]
        scale = kwargs["ç¼©æ”¾æ¯”ä¾‹"]
        aspect = kwargs["ç›®æ ‡é•¿å®½æ¯”"]
        max_side = kwargs["æœ€å¤§è¾¹é•¿é™åˆ¶"]
        ensure_multiple = kwargs["ç¡®ä¿8çš„å€æ•°"]
        
        if mode == "å›ºå®šåˆ†è¾¨ç‡":
            new_width, new_height = width, height
        elif mode == "æŒ‰é•¿å®½æ¯”" and aspect != "ä¿æŒåŸæ¯”ä¾‹":
            if ":" in aspect:
                w_ratio, h_ratio = map(int, aspect.split(":"))
                new_width, new_height = ImageUtils.calculate_optimal_size(
                    width, height,
                    target_aspect_ratio=(w_ratio, h_ratio),
                    max_side=max_side,
                    multiple_of=8 if ensure_multiple else 1
                )
            else:
                new_width, new_height = width, height
        else:
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            if max(new_width, new_height) > max_side:
                scale_factor = max_side / max(new_width, new_height)
                new_width = int(new_width * scale_factor)
                new_height = int(new_height * scale_factor)
        
        if ensure_multiple:
            new_width = new_width - (new_width % 8)
            new_height = new_height - (new_height % 8)
        
        info = ImageUtils.get_resolution_info(new_width, new_height)
        info_str = (
            f"ğŸ“ åˆ†è¾¨ç‡: {new_width} Ã— {new_height}\n"
            f"ğŸ”³ é•¿å®½æ¯”: {info['aspect_name']}\n"
            f"ğŸ“Š åƒç´ : {info['megapixels']} MP ({info['resolution_level']})\n"
            f"ğŸ“± æ–¹å‘: {'æ¨ªç‰ˆ ğŸŒ„' if info['is_landscape'] else 'ç«–ç‰ˆ ğŸ“±' if info['is_portrait'] else 'æ­£æ–¹å½¢ â¬œ'}"
        )
        
        return (new_width, new_height, info_str)

class ResolutionAnalyzer(BaseResolutionNode):
    """åˆ†è¾¨ç‡åˆ†æå™¨"""
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        return {
            "required": {
                "å®½åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "é«˜åº¦": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("åˆ†è¾¨ç‡ä¿¡æ¯",)
    FUNCTION = "analyze_resolution"
    CATEGORY = "ResolutionPresets"
    
    def analyze_resolution(self, å®½åº¦, é«˜åº¦):
        info = ImageUtils.get_resolution_info(å®½åº¦, é«˜åº¦)
        
        info_str = (
            f"åˆ†è¾¨ç‡: {info['width']}Ã—{info['height']} ({info['aspect_name']})\n"
            f"åƒç´ : {info['megapixels']}MP â€¢ ç­‰çº§: {info['resolution_level']}\n"
            f"æ–¹å‘: {'æ¨ªç‰ˆ ğŸŒ„' if info['is_landscape'] else 'ç«–ç‰ˆ ğŸ“±' if info['is_portrait'] else 'æ­£æ–¹å½¢ â¬œ'}"
        )
        
        return (info_str,)

# ========== èŠ‚ç‚¹æ³¨å†Œ ==========

NODE_CLASS_MAPPINGS = {
    "ResolutionPresetImage": ResolutionPresetImage,
    "ResolutionPresetLatent": ResolutionPresetLatent,
    "ResolutionPresetSetter": ResolutionPresetSetter,
    "ResolutionCalculator": ResolutionCalculator,
    "ResolutionAnalyzer": ResolutionAnalyzer,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ResolutionPresetImage": "åˆ†è¾¨ç‡é¢„è®¾ - å›¾åƒ",
    "ResolutionPresetLatent": "åˆ†è¾¨ç‡é¢„è®¾ - æ½œåœ¨ç©ºé—´",
    "ResolutionPresetSetter": "åˆ†è¾¨ç‡é¢„è®¾å™¨",
    "ResolutionCalculator": "åˆ†è¾¨ç‡è®¡ç®—å™¨",
    "ResolutionAnalyzer": "åˆ†è¾¨ç‡åˆ†æå™¨",
}
